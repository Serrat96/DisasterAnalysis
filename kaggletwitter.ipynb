{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "kaggletwitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbnCtyv1VsYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971bf0c9-3a77-45f8-ccbb-7bb68fdd70b6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from scipy import stats\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import KNNImputer\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8gPAzuVsYH"
      },
      "source": [
        "X_train = pd.read_csv(\"train.csv\")\n",
        "X_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqVRvh7_VsYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c17b0775-bfe8-468e-cbc6-474d87aa6487"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   8     NaN  ...  #RockyFire Update => California Hwy. 20 closed...      1\n",
              "4  13     NaN  ...  I'm on top of the hill and I can see a fire in...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DZARCZUVsYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f57f791-a9ca-4491-ac9e-5ae91181ee98"
      },
      "source": [
        "X_train[X_train['target']==1]['text']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Our Deeds are the Reason of this #earthquake M...\n",
              "1                  Forest fire near La Ronge Sask. Canada\n",
              "2       All residents asked to 'shelter in place' are ...\n",
              "3       #RockyFire Update => California Hwy. 20 closed...\n",
              "4       I'm on top of the hill and I can see a fire in...\n",
              "                              ...                        \n",
              "5341    Suicide bomber kills 15 in Saudi security site...\n",
              "5342    Two giant cranes holding a bridge collapse int...\n",
              "5343    @aria_ahrary @TheTawniest The out of control w...\n",
              "5344    Police investigating after an e-bike collided ...\n",
              "5345    The Latest: More Homes Razed by Northern Calif...\n",
              "Name: text, Length: 2291, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQbgZrXhVsYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b8eeb8-09d2-4c37-fbe7-5443bbb76549"
      },
      "source": [
        "X_train[X_train['target']==0]['text']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8                                          What's up man?\n",
              "9                                           I love fruits\n",
              "10                                       Summer is lovely\n",
              "11                                      My car is so fast\n",
              "12                                 this is ridiculous....\n",
              "                              ...                        \n",
              "5325    @widda16 ... He's gone. You can relax. I thoug...\n",
              "5326     @jt_ruff23 @cameronhacker and I wrecked you both\n",
              "5327    Three days off from work and they've pretty mu...\n",
              "5328    @engineshed Great atmosphere at the British Li...\n",
              "5329    Cramer: Iger's 3 words that wrecked Disney's s...\n",
              "Name: text, Length: 3055, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3CwMx-JVsYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f436a0a-9dcc-4c33-915a-412fdb6fecd3"
      },
      "source": [
        "print('X_train.shape(sin procesar): ', X_train.shape)\n",
        "print('X_test.shape(sin procesar): ', X_test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape(sin procesar):  (5286, 5)\n",
            "X_test.shape(sin procesar):  (2247, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4WxVtSUVsYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08992242-9d6b-4975-e8db-5d0346a26821"
      },
      "source": [
        "# Eliminamos los duplicados\n",
        "X_train = X_train.drop_duplicates(subset='text')\n",
        "print('X_train.shape(sin duplicados): ', X_train.shape)\n",
        "X_test = X_test.drop_duplicates(subset='text')\n",
        "print('X_test.shape(sin duplicados): ', X_test.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape(sin duplicados):  (5286, 5)\n",
            "X_test.shape(sin duplicados):  (2247, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzFsuxoltUN7",
        "outputId": "56e8ed6c-3752-4790-a885-a635fb3c96d6"
      },
      "source": [
        "import re\n",
        "\n",
        "signos = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\>)|(\\=)|(\\<)\")\n",
        "signos_arroba = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\>)|(\\=)|(\\<)|(\\@)\")\n",
        "\n",
        "def signs_tweets(tweet):\n",
        "    return signos.sub('', tweet.lower())\n",
        "\n",
        "X_train['text'] = X_train['text'].apply(signs_tweets)\n",
        "X_train['text'].head()\n",
        "X_test['text'] = X_test['text'].apply(signs_tweets)\n",
        "X_test['text'].head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     people receive #wildfires evacuation orders i...\n",
              "1    just got sent this photo from ruby #alaska as ...\n",
              "2    #flood #disaster heavy rain causes flash flood...\n",
              "3    there's an emergency evacuation happening now ...\n",
              "4    i'm afraid that the tornado is coming to our area\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldH7sKX0VsYM"
      },
      "source": [
        "def remove_links(df):\n",
        "    return \" \".join(['{link}' if ('http') in word else word for word in df.split()])\n",
        "\n",
        "X_train['text'] = X_train['text'].apply(remove_links)\n",
        "X_test['text'] = X_test['text'].apply(remove_links)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C3v0AEU8tnII",
        "outputId": "e7a86c96-111d-488f-ce7e-a80c8179a49e"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(df):\n",
        "    return \" \".join([word for word in df.split() if word not in english_stopwords])\n",
        "\n",
        "X_train['text'] = X_train['text'].apply(remove_stopwords)\n",
        "X_train.head()\n",
        "X_test['text'] = X_test['text'].apply(remove_stopwords)\n",
        "X_test.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>people receive #wildfires evacuation orders ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>got sent photo ruby #alaska smoke #wildfires p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there's emergency evacuation happening buildin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i'm afraid tornado coming area</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   6     NaN      NaN  people receive #wildfires evacuation orders ca...\n",
              "1   7     NaN      NaN  got sent photo ruby #alaska smoke #wildfires p...\n",
              "2  10     NaN      NaN  #flood #disaster heavy rain causes flash flood...\n",
              "3  14     NaN      NaN  there's emergency evacuation happening buildin...\n",
              "4  15     NaN      NaN                     i'm afraid tornado coming area"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMxzYszzVsYO"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "def english_stemmer(x):\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    return ' '.join([stemmer.stem(word) for word in x.split()])\n",
        "\n",
        "X_train['text'] = X_train['text'].apply(english_stemmer)\n",
        "X_test['text'] = X_test['text'].apply(english_stemmer)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrEtB_cjVsYP"
      },
      "source": [
        "X_train = X_train[['text', 'target']]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eakwajl3VsYQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgBucXedVsYQ"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('cls', LinearSVC())\n",
        "])\n",
        "\n",
        "# Aqui definimos el espacio de par√°metros a explorar\n",
        "parameters = {\n",
        "    'vect__max_df': (0.5, 1.9),\n",
        "    'vect__min_df': (10, 20,50),\n",
        "    'vect__max_features': (500, 1000),\n",
        "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigramas or bigramas\n",
        "    'cls__C': (0.2, 0.5, 0.7),\n",
        "    'cls__loss': ('hinge', 'squared_hinge'),\n",
        "    'cls__max_iter': (500, 1000)\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(pipeline,\n",
        "                          parameters,\n",
        "                          cv=5,\n",
        "                          n_jobs=-1,\n",
        "                          scoring='roc_auc')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok27jJGfVsYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b56611-fa85-45f1-f584-09e7e783bebd"
      },
      "source": [
        "grid_search.fit(X_train['text'], X_train['target'])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(?u)...\n",
              "                                                  verbose=0))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'cls__C': (0.2, 0.5, 0.7),\n",
              "                         'cls__loss': ('hinge', 'squared_hinge'),\n",
              "                         'cls__max_iter': (500, 1000),\n",
              "                         'vect__max_df': (0.5, 1.9),\n",
              "                         'vect__max_features': (500, 1000),\n",
              "                         'vect__min_df': (10, 20, 50),\n",
              "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLQk3r1SVsYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55275df-7148-48bd-b95f-7647ffc537d4"
      },
      "source": [
        "print(\"Best params:\", grid_search.best_params_)\n",
        "print(\"Best acc:\", grid_search.best_score_)\n",
        "print(\"Best model:\", grid_search.best_estimator_)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 1000, 'vect__max_df': 1.9, 'vect__max_features': 1000, 'vect__min_df': 10, 'vect__ngram_range': (1, 2)}\n",
            "Best acc: 0.7248453190238058\n",
            "Best model: Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer='word', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.9,\n",
            "                                 max_features=1000, min_df=10,\n",
            "                                 ngram_range=(1, 2), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                 tokenizer=None, vocabulary=None)),\n",
            "                ('cls',\n",
            "                 LinearSVC(C=0.2, class_weight=None, dual=True,\n",
            "                           fit_intercept=True, intercept_scaling=1,\n",
            "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
            "                           penalty='l2', random_state=None, tol=0.0001,\n",
            "                           verbose=0))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXzZWL7XvKc6",
        "outputId": "4e43d0b4-7247-4e4f-84de-e9b1597bf0bb"
      },
      "source": [
        "grid_search.predict(X_test['text'])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPME4A8xVsYR"
      },
      "source": [
        "df_train = pd.read_csv(\"data_twitter/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmF6DeXxVsYR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nQg4co0VsYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4bbf6907-7f57-4296-d097-0d23cc5ab1e9"
      },
      "source": [
        "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n",
        "# you could use any filename. We choose submission here\n",
        "my_submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-53c1470d1c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_prices\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# you could use any filename. We choose submission here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmy_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChG0BFaSp5wt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}