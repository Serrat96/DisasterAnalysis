{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "CbnCtyv1VsYE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "4V8gPAzuVsYH"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train.csv\")\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HqVRvh7_VsYI",
    "outputId": "3a4db2ec-cfe4-4f8f-eb49-d3f46f924efe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "4  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DZARCZUVsYJ",
    "outputId": "003a529c-c5c9-4626-b7c2-5b031663eff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       #RockyFire Update => California Hwy. 20 closed...\n",
       "4       I'm on top of the hill and I can see a fire in...\n",
       "                              ...                        \n",
       "5341    Suicide bomber kills 15 in Saudi security site...\n",
       "5342    Two giant cranes holding a bridge collapse int...\n",
       "5343    @aria_ahrary @TheTawniest The out of control w...\n",
       "5344    Police investigating after an e-bike collided ...\n",
       "5345    The Latest: More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 2291, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train['target']==1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQbgZrXhVsYK",
    "outputId": "a29a42dd-cb9b-46d0-f382-2e6976f2607f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8                                          What's up man?\n",
       "9                                           I love fruits\n",
       "10                                       Summer is lovely\n",
       "11                                      My car is so fast\n",
       "12                                 this is ridiculous....\n",
       "                              ...                        \n",
       "5325    @widda16 ... He's gone. You can relax. I thoug...\n",
       "5326     @jt_ruff23 @cameronhacker and I wrecked you both\n",
       "5327    Three days off from work and they've pretty mu...\n",
       "5328    @engineshed Great atmosphere at the British Li...\n",
       "5329    Cramer: Iger's 3 words that wrecked Disney's s...\n",
       "Name: text, Length: 3055, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train['target']==0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3CwMx-JVsYK",
    "outputId": "7339c528-6088-4eee-e4aa-33895f1f62eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape(sin procesar):  (5346, 5)\n",
      "X_test.shape(sin procesar):  (2267, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape(sin procesar): ', X_train.shape)\n",
    "print('X_test.shape(sin procesar): ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4WxVtSUVsYL",
    "outputId": "f891d2db-1965-4a67-ef06-049151099a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape(sin duplicados):  (5286, 5)\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos los duplicados\n",
    "X_train = X_train.drop_duplicates(subset='text')\n",
    "print('X_train.shape(sin duplicados): ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzFsuxoltUN7",
    "outputId": "80251433-6bda-431a-c1f2-f8a04816d1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     people receive #wildfires evacuation orders i...\n",
       "1    just got sent this photo from ruby #alaska as ...\n",
       "2    #flood #disaster heavy rain causes flash flood...\n",
       "3    there's an emergency evacuation happening now ...\n",
       "4    i'm afraid that the tornado is coming to our area\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "signos = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\>)|(\\=)|(\\<)\")\n",
    "signos_arroba = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\>)|(\\=)|(\\<)|(\\@)\")\n",
    "\n",
    "def signs_tweets(tweet):\n",
    "    return signos.sub('', tweet.lower())\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(signs_tweets)\n",
    "X_train['text'].head()\n",
    "X_test['text'] = X_test['text'].apply(signs_tweets)\n",
    "X_test['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "ldH7sKX0VsYM"
   },
   "outputs": [],
   "source": [
    "def remove_links(df):\n",
    "    return \" \".join(['{link}' if ('http') in word else word for word in df.split()])\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(remove_links)\n",
    "X_test['text'] = X_test['text'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C3v0AEU8tnII",
    "outputId": "a242bcb9-bd2c-4631-c013-77573b56da56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive #wildfires evacuation orders ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby #alaska smoke #wildfires p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there's emergency evacuation happening buildin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm afraid tornado coming area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   6     NaN      NaN  people receive #wildfires evacuation orders ca...\n",
       "1   7     NaN      NaN  got sent photo ruby #alaska smoke #wildfires p...\n",
       "2  10     NaN      NaN  #flood #disaster heavy rain causes flash flood...\n",
       "3  14     NaN      NaN  there's emergency evacuation happening buildin...\n",
       "4  15     NaN      NaN                     i'm afraid tornado coming area"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    return \" \".join([word for word in df.split() if word not in english_stopwords])\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(remove_stopwords)\n",
    "X_train.head()\n",
    "X_test['text'] = X_test['text'].apply(remove_stopwords)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "OMxzYszzVsYO"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def english_stemmer(x):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return ' '.join([stemmer.stem(word) for word in x.split()])\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(english_stemmer)\n",
    "X_test['text'] = X_test['text'].apply(english_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def get_lemmatized_text(corpus):\\n    from nltk.stem import WordNetLemmatizer\\n    lemmatizer = WordNetLemmatizer()\\n    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\\n# Lematizamos las reviews\\nX_train['text'] = X_train['text'].apply(get_lemmatized_text)\\nX_test['text'] = X_test['text'].apply(get_lemmatized_text)\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "# Lematizamos las reviews\n",
    "X_train['text'] = X_train['text'].apply(get_lemmatized_text)\n",
    "X_test['text'] = X_test['text'].apply(get_lemmatized_text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import nltk\\n\\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\\nlemmatizer = nltk.stem.WordNetLemmatizer()\\n\\ndef lemmatize_text(text):\\n    cadena = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\\n    return ' '.join(cadena)\\n\\nX_train[['text']] = X_train[['text']].text.apply(lemmatize_text)\\nX_test[['text']] = X_test[['text']].text.apply(lemmatize_text)\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    cadena = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    return ' '.join(cadena)\n",
    "\n",
    "X_train[['text']] = X_train[['text']].text.apply(lemmatize_text)\n",
    "X_test[['text']] = X_test[['text']].text.apply(lemmatize_text)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason #earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#rockyfir updat california hwi close direct du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm top hill see fire wood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN         deed reason #earthquak may allah forgiv us   \n",
       "1   4     NaN      NaN               forest fire near la rong sask canada   \n",
       "2   5     NaN      NaN  resid ask shelter place notifi offic evacu she...   \n",
       "3   8     NaN      NaN  #rockyfir updat california hwi close direct du...   \n",
       "4  13     NaN      NaN                         i'm top hill see fire wood   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv #wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi #alaska smoke #wildfir pou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disast heavi rain caus flash flood str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there emerg evacu happen build across street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm afraid tornado come area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   6     NaN      NaN       peopl receiv #wildfir evacu order california\n",
       "1   7     NaN      NaN  got sent photo rubi #alaska smoke #wildfir pou...\n",
       "2  10     NaN      NaN  #flood #disast heavi rain caus flash flood str...\n",
       "3  14     NaN      NaN       there emerg evacu happen build across street\n",
       "4  15     NaN      NaN                       i'm afraid tornado come area"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['text', 'target']]\n",
    "X_test = X_test[['id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deed reason #earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#rockyfir updat california hwi close direct du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'm top hill see fire wood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0         deed reason #earthquak may allah forgiv us       1\n",
       "1               forest fire near la rong sask canada       1\n",
       "2  resid ask shelter place notifi offic evacu she...       1\n",
       "3  #rockyfir updat california hwi close direct du...       1\n",
       "4                         i'm top hill see fire wood       1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "fnXqVO-A2pZK",
    "outputId": "5b6f9964-2146-4068-c088-1e7436b80e69"
   },
   "outputs": [],
   "source": [
    "\"\"\"vectorizer = CountVectorizer(binary=True)\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\"\"\"\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "rMX9zklky3Vu"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', SVC(probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "XgBucXedVsYQ"
   },
   "outputs": [],
   "source": [
    "# Aqui definimos el espacio de parámetros a explorar\n",
    "parameters = {\n",
    "    'vect__max_df': (0.7, 0.9),\n",
    "    'vect__min_df': (0.01, 0.05),\n",
    "    'vect__max_features': (500, 1000, 2500),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigramas or bigramas\n",
    "    'cls__C': (0.2, 0.5, 0.7),\n",
    "    'cls__degree': [1,2,3,4],\n",
    "    'cls__gamma': [0.1, \"auto\", 1, 10]\n",
    "}\n",
    "\n",
    "parameters_low = {\n",
    "    'vect__max_df': (0.4, 0.6),\n",
    "    'vect__min_df': (0.01, 0.02),\n",
    "    'vect__max_features': (500, 'auto', 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigramas or bigramas\n",
    "    'cls__C': (2, 3),\n",
    "    'cls__degree': [0.2, 0.3],\n",
    "    'cls__gamma': ['auto', 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                          parameters_low,\n",
    "                          cv=5,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "Ok27jJGfVsYR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('cls', SVC(probability=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cls__C': (2, 3), 'cls__degree': [0.2, 0.3],\n",
       "                         'cls__gamma': ['auto', 0.1],\n",
       "                         'vect__max_df': (0.4, 0.6),\n",
       "                         'vect__max_features': (500, 'auto', 1000),\n",
       "                         'vect__min_df': (0.01, 0.02),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train['text'], X_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "uLQk3r1SVsYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'cls__C': 3, 'cls__degree': 0.2, 'cls__gamma': 'auto', 'vect__max_df': 0.6, 'vect__max_features': 500, 'vect__min_df': 0.01, 'vect__ngram_range': (1, 2)}\n",
      "Best acc: 0.7225286732394057\n",
      "Best model: Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.6, max_features=500, min_df=0.01,\n",
      "                                 ngram_range=(1, 2))),\n",
      "                ('cls', SVC(C=3, degree=0.2, gamma='auto', probability=True))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best acc:\", grid_search.best_score_)\n",
    "print(\"Best model:\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "zXzZWL7XvKc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = grid_search.predict_proba(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37973068, 0.62026932],\n",
       "       [0.79578997, 0.20421003],\n",
       "       [0.13885296, 0.86114704],\n",
       "       ...,\n",
       "       [0.45497058, 0.54502942],\n",
       "       [0.64244885, 0.35755115],\n",
       "       [0.63507288, 0.36492712]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2267, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = X_test[['id']]\n",
    "df_submission['target'] = predict_proba[:,-1]\n",
    "df_submission.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "kaggletwitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
